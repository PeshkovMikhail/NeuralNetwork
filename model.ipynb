{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linear import *\n",
    "from convolutional import *\n",
    "from activations import *\n",
    "from loss import CategoricalCrossEntropyLoss\n",
    "import mnist\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistConv:\n",
    "    def __init__(self, lr = 0.01) -> None:\n",
    "        self.layers = [\n",
    "            ConvLayer(1, 32, 5, activaton=ReLu()),\n",
    "            MaxPool(2),\n",
    "            Flatten(),\n",
    "            Linear(32*12**2, 64, Sigmoid()),\n",
    "            Linear(64, 10, None)\n",
    "        ]\n",
    "        self.lr = lr\n",
    "        self.res = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        self.res = x\n",
    "        return x\n",
    "    \n",
    "    def backward(self, expected_output):\n",
    "        loss = CategoricalCrossEntropyLoss()\n",
    "        loss_val = loss(self.res, expected_output)\n",
    "        err = loss.derivatives()\n",
    "        for layer in reversed(self.layers):\n",
    "            err = layer.backward(err, self.lr)\n",
    "        return loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, t_train, x_test, t_test = mnist.load()\n",
    "model = MnistConv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0/3\n",
      "epoch: 0.1, loss: 1.2800874304934964\n",
      "epoch: 0.2, loss: 0.7344519608392068\n",
      "epoch: 0.3, loss: 0.658066691984265\n",
      "epoch: 0.4, loss: 0.547573084073393\n",
      "epoch: 0.5, loss: 0.575709893340678\n",
      "epoch: 0.6, loss: 0.5663411528953972\n",
      "epoch: 0.7, loss: 0.4736537406703636\n",
      "epoch: 0.8, loss: 0.5023362560985972\n",
      "epoch: 0.9, loss: 0.5103001539766407\n",
      "epoch 1/3\n",
      "epoch: 1.1, loss: 0.41613088492660555\n",
      "epoch: 1.2, loss: 0.40069498509373513\n",
      "epoch: 1.3, loss: 0.43465365758475943\n",
      "epoch: 1.4, loss: 0.3479516539678411\n",
      "epoch: 1.5, loss: 0.40850393425053894\n",
      "epoch: 1.6, loss: 0.4061290864667609\n",
      "epoch: 1.7, loss: 0.3715212503752108\n",
      "epoch: 1.8, loss: 0.39686237637771776\n",
      "epoch: 1.9, loss: 0.37271340876648906\n",
      "epoch 2/3\n",
      "epoch: 2.1, loss: 0.34594245337745755\n",
      "epoch: 2.2, loss: 0.3514578356331633\n",
      "epoch: 2.3, loss: 0.35791449817347326\n",
      "epoch: 2.4, loss: 0.29751558132017986\n",
      "epoch: 2.5, loss: 0.3199872592068827\n",
      "epoch: 2.6, loss: 0.3016144889189218\n",
      "epoch: 2.7, loss: 0.2935946364061692\n",
      "epoch: 2.8, loss: 0.3236257106341769\n",
      "epoch: 2.9, loss: 0.3056338651668891\n"
     ]
    }
   ],
   "source": [
    "EPOCHES = 3\n",
    "\n",
    "for epoch in range(EPOCHES):\n",
    "    print(f\"epoch {epoch}/{EPOCHES}\")\n",
    "    loss_val = 0\n",
    "    for i, (img, label) in enumerate(zip(x_train, t_train)):\n",
    "\n",
    "        res = model.forward(img.reshape((1, 1, 28, 28))/255.0)\n",
    "        loss_val += model.backward(label)\n",
    "        if i % 6000 == 0 and i > 0:\n",
    "            print(f\"epoch: {epoch}.{i//6000}, loss: {loss_val/6000}\")\n",
    "            loss_val = 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 955. 1110.  910.  949.  831.  787.  892.  909.  842.  950.]\n",
      "[ 980. 1135. 1032. 1010.  982.  892.  958. 1028.  974. 1009.]\n",
      "[1025. 1140.  975. 1100.  885.  849.  960.  966.  904. 1196.]\n"
     ]
    }
   ],
   "source": [
    "results = np.zeros((3, 10))\n",
    "for (img, label) in zip(x_test, t_test):\n",
    "    results[0][label] += 1\n",
    "    r = model.forward(img.reshape((1, 1, 28, 28))/255.0)\n",
    "    if np.argmax(r, axis = 1) == label:\n",
    "        results[1][label] +=1\n",
    "    results[2][np.argmax(r, axis = 1)] += 1\n",
    "\n",
    "print(results[1])\n",
    "print(results[0])\n",
    "print(results[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9135"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(results[1])/np.sum(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9744898 , 0.97797357, 0.88178295, 0.93960396, 0.84623218,\n",
       "       0.882287  , 0.93110647, 0.88424125, 0.86447639, 0.94152626])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[1]/results[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
