{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linear import *\n",
    "from convolutional import *\n",
    "from activations import *\n",
    "from loss import CategoricalCrossEntropyLoss\n",
    "import mnist\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistConv:\n",
    "    def __init__(self, lr = 0.01) -> None:\n",
    "        self.layers = [\n",
    "            ConvLayer(1, 32, 5, activaton=ReLu()),\n",
    "            MaxPool(2),\n",
    "            Flatten(),\n",
    "            Linear(32*12**2, 64, Sigmoid()),\n",
    "            Linear(64, 10, None)\n",
    "        ]\n",
    "        self.lr = lr\n",
    "        self.res = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        self.res = x\n",
    "        return x\n",
    "    \n",
    "    def backward(self, expected_output):\n",
    "        loss = CategoricalCrossEntropyLoss()\n",
    "        loss_val = loss(self.res, expected_output)\n",
    "        err = loss.derivatives()\n",
    "        for layer in reversed(self.layers):\n",
    "            err = layer.backward(err, self.lr)\n",
    "        return loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, t_train, x_test, t_test = mnist.load()\n",
    "model = MnistConv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0/3\n",
      "epoch: 0.1.0, loss: 3.199688172315947\n",
      "epoch: 0.2.0, loss: 2.2314858475308976\n",
      "epoch: 0.3.0, loss: 2.021405788811015\n",
      "epoch: 0.4.0, loss: 1.5823702095279293\n",
      "epoch: 0.5.0, loss: 1.8816727679706833\n",
      "epoch: 0.6.0, loss: 2.1217259969299236\n",
      "epoch: 0.7.0, loss: 1.929911914713228\n",
      "epoch: 0.8.0, loss: 1.6655691875115846\n",
      "epoch: 0.9.0, loss: 1.8361567768318605\n",
      "epoch: 0.10.0, loss: 1.8168993566179426\n",
      "epoch: 0.11.0, loss: 1.8148235418658456\n",
      "epoch: 0.12.0, loss: 1.528723670805916\n",
      "epoch: 0.13.0, loss: 1.5329643781380033\n",
      "epoch: 0.14.0, loss: 1.4491535657778383\n",
      "epoch: 0.15.0, loss: 1.406615574401152\n",
      "epoch: 0.16.0, loss: 1.5046553666662836\n",
      "epoch: 0.17.0, loss: 1.2025224937734946\n",
      "epoch: 0.18.0, loss: 1.2096568604376552\n",
      "epoch: 0.19.0, loss: 1.1817918193327244\n",
      "epoch: 0.20.0, loss: 1.38739562114119\n",
      "epoch: 0.21.0, loss: 1.2520921024059386\n",
      "epoch: 0.22.0, loss: 1.0916106636094969\n",
      "epoch: 0.23.0, loss: 1.2802884430673243\n",
      "epoch: 0.24.0, loss: 1.1094613274095828\n",
      "epoch: 0.25.0, loss: 1.1986670306913965\n",
      "epoch: 0.26.0, loss: 1.0564528461226472\n",
      "epoch: 0.27.0, loss: 1.0157414324357774\n",
      "epoch: 0.28.0, loss: 1.4287558315518434\n",
      "epoch: 0.29.0, loss: 1.1703793238703963\n",
      "epoch: 0.30.0, loss: 1.2268418693203103\n",
      "epoch: 0.31.0, loss: 1.2613413331443333\n",
      "epoch: 0.32.0, loss: 1.1087577932390233\n",
      "epoch: 0.33.0, loss: 0.9198921286040257\n",
      "epoch: 0.34.0, loss: 1.0829083030247042\n",
      "epoch: 0.35.0, loss: 0.9804136371490135\n",
      "epoch: 0.36.0, loss: 1.0948335045925934\n",
      "epoch: 0.37.0, loss: 1.227536236173308\n",
      "epoch: 0.38.0, loss: 1.0304861290847487\n",
      "epoch: 0.39.0, loss: 1.0334931164271455\n",
      "epoch: 0.40.0, loss: 1.1538826587700433\n",
      "epoch: 0.41.0, loss: 0.9776601074798199\n",
      "epoch: 0.42.0, loss: 1.1080941101934807\n",
      "epoch: 0.43.0, loss: 1.0440571150237898\n",
      "epoch: 0.44.0, loss: 1.0925785760051576\n",
      "epoch: 0.45.0, loss: 0.9761382485661879\n",
      "epoch: 0.46.0, loss: 0.6868962084950317\n",
      "epoch: 0.47.0, loss: 1.13627607734159\n",
      "epoch: 0.48.0, loss: 1.0175882513993983\n",
      "epoch: 0.49.0, loss: 0.9382095040743691\n",
      "epoch: 0.50.0, loss: 1.2540847981079437\n",
      "epoch: 0.51.0, loss: 0.9210680401526998\n",
      "epoch: 0.52.0, loss: 1.0228825076842518\n",
      "epoch: 0.53.0, loss: 0.8890594383417861\n",
      "epoch: 0.54.0, loss: 1.101254488985593\n",
      "epoch: 0.55.0, loss: 0.8266395008561165\n",
      "epoch: 0.56.0, loss: 0.7915892846223975\n",
      "epoch: 0.57.0, loss: 0.7537060187471079\n",
      "epoch: 0.58.0, loss: 1.066464464268679\n",
      "epoch: 0.59.0, loss: 1.0726805141720843\n",
      "epoch: 0.60.0, loss: 0.8992939532973984\n",
      "epoch: 0.61.0, loss: 0.8543499705735517\n",
      "epoch: 0.62.0, loss: 0.8307688850254742\n",
      "epoch: 0.63.0, loss: 0.9289828424311682\n",
      "epoch: 0.64.0, loss: 0.9024273550217967\n",
      "epoch: 0.65.0, loss: 0.8833370222054251\n",
      "epoch: 0.66.0, loss: 0.6932712772853433\n",
      "epoch: 0.67.0, loss: 0.70976349007402\n",
      "epoch: 0.68.0, loss: 0.805636950203216\n",
      "epoch: 0.69.0, loss: 0.9592831928914259\n",
      "epoch: 0.70.0, loss: 0.9182389552104047\n",
      "epoch: 0.71.0, loss: 0.8154892070832659\n",
      "epoch: 0.72.0, loss: 0.8022408910915846\n",
      "epoch: 0.73.0, loss: 1.2706755719649612\n",
      "epoch: 0.74.0, loss: 1.0496426574113018\n",
      "epoch: 0.75.0, loss: 0.9567867759474106\n",
      "epoch: 0.76.0, loss: 0.830101109212171\n",
      "epoch: 0.77.0, loss: 0.8186941574654766\n",
      "epoch: 0.78.0, loss: 0.7438189101766294\n",
      "epoch: 0.79.0, loss: 0.8283610151831248\n",
      "epoch: 0.80.0, loss: 0.7557256824534684\n",
      "epoch: 0.81.0, loss: 0.6648878734182913\n",
      "epoch: 0.82.0, loss: 0.7250717379012496\n",
      "epoch: 0.83.0, loss: 0.9576297434710794\n",
      "epoch: 0.84.0, loss: 0.6125219865408638\n",
      "epoch: 0.85.0, loss: 0.7862578480575728\n",
      "epoch: 0.86.0, loss: 0.5770634894422182\n",
      "epoch: 0.87.0, loss: 0.9881865451520302\n",
      "epoch: 0.88.0, loss: 1.146861944445083\n",
      "epoch: 0.89.0, loss: 1.0096606460528308\n",
      "epoch: 0.90.0, loss: 0.6865611221763175\n",
      "epoch: 0.91.0, loss: 0.6023201067241603\n",
      "epoch: 0.92.0, loss: 0.6294650813251345\n",
      "epoch: 0.93.0, loss: 0.6846789300746953\n",
      "epoch: 0.94.0, loss: 0.7139986451731953\n",
      "epoch: 0.95.0, loss: 0.7015782104284415\n",
      "epoch: 0.96.0, loss: 0.7210695739328701\n",
      "epoch: 0.97.0, loss: 0.5699759034117176\n",
      "epoch: 0.98.0, loss: 0.6838808072042906\n",
      "epoch: 0.99.0, loss: 0.49861692496192817\n",
      "epoch 1/3\n",
      "epoch: 1.1.0, loss: 0.7346292675822909\n",
      "epoch: 1.2.0, loss: 0.79663005816619\n",
      "epoch: 1.3.0, loss: 0.596394980450669\n",
      "epoch: 1.4.0, loss: 0.3956680485513237\n",
      "epoch: 1.5.0, loss: 0.5222878679950378\n",
      "epoch: 1.6.0, loss: 0.7701971236651501\n",
      "epoch: 1.7.0, loss: 0.7405872092134714\n",
      "epoch: 1.8.0, loss: 0.7613721911265198\n",
      "epoch: 1.9.0, loss: 0.9275819671019998\n",
      "epoch: 1.10.0, loss: 0.7193031222652441\n",
      "epoch: 1.11.0, loss: 0.8806450114715976\n",
      "epoch: 1.12.0, loss: 0.6853084777735811\n",
      "epoch: 1.13.0, loss: 0.7544919100255769\n",
      "epoch: 1.14.0, loss: 0.6685065718725789\n",
      "epoch: 1.15.0, loss: 0.6035270141638702\n",
      "epoch: 1.16.0, loss: 0.8615650500514207\n",
      "epoch: 1.17.0, loss: 0.5493555167253442\n",
      "epoch: 1.18.0, loss: 0.515131162464114\n",
      "epoch: 1.19.0, loss: 0.5636571722381175\n",
      "epoch: 1.20.0, loss: 0.5146779633747491\n",
      "epoch: 1.21.0, loss: 0.6468585736359564\n",
      "epoch: 1.22.0, loss: 0.4910584885933487\n",
      "epoch: 1.23.0, loss: 0.5806138067584363\n",
      "epoch: 1.24.0, loss: 0.5206860638788142\n",
      "epoch: 1.25.0, loss: 0.6169335108178211\n",
      "epoch: 1.26.0, loss: 0.44169798090891355\n",
      "epoch: 1.27.0, loss: 0.5805765639924958\n",
      "epoch: 1.28.0, loss: 0.5849570525590708\n",
      "epoch: 1.29.0, loss: 0.6173171537420103\n",
      "epoch: 1.30.0, loss: 0.5943955743320906\n",
      "epoch: 1.31.0, loss: 0.7217709993057517\n",
      "epoch: 1.32.0, loss: 0.5139913709276217\n",
      "epoch: 1.33.0, loss: 0.5990625796206589\n",
      "epoch: 1.34.0, loss: 0.5947025341412856\n",
      "epoch: 1.35.0, loss: 0.5998148886691653\n",
      "epoch: 1.36.0, loss: 0.6336423837353583\n",
      "epoch: 1.37.0, loss: 0.7116361016773961\n",
      "epoch: 1.38.0, loss: 0.5651861264180313\n",
      "epoch: 1.39.0, loss: 0.6449395327429202\n",
      "epoch: 1.40.0, loss: 0.4216897852230539\n",
      "epoch: 1.41.0, loss: 0.5594722267146245\n",
      "epoch: 1.42.0, loss: 0.6005738193251582\n",
      "epoch: 1.43.0, loss: 0.4655861851367175\n",
      "epoch: 1.44.0, loss: 0.5620048545973584\n",
      "epoch: 1.45.0, loss: 0.4921361599768829\n",
      "epoch: 1.46.0, loss: 0.4359813040615696\n",
      "epoch: 1.47.0, loss: 0.6464502851434178\n",
      "epoch: 1.48.0, loss: 0.517052439607695\n",
      "epoch: 1.49.0, loss: 0.6517442509968481\n",
      "epoch: 1.50.0, loss: 0.7540572734295375\n",
      "epoch: 1.51.0, loss: 0.6426544439787593\n",
      "epoch: 1.52.0, loss: 0.7569807390513502\n",
      "epoch: 1.53.0, loss: 0.556011196819566\n",
      "epoch: 1.54.0, loss: 0.6909420741201479\n",
      "epoch: 1.55.0, loss: 0.504759417024319\n",
      "epoch: 1.56.0, loss: 0.5810428068177838\n",
      "epoch: 1.57.0, loss: 0.5951906711471906\n",
      "epoch: 1.58.0, loss: 0.6367182820958619\n",
      "epoch: 1.59.0, loss: 0.7386273330084876\n",
      "epoch: 1.60.0, loss: 0.5749830920936296\n",
      "epoch: 1.61.0, loss: 0.46013781969538237\n",
      "epoch: 1.62.0, loss: 0.5045289189661544\n",
      "epoch: 1.63.0, loss: 0.6434971397094058\n",
      "epoch: 1.64.0, loss: 0.44921791639616304\n",
      "epoch: 1.65.0, loss: 0.5090743623878188\n",
      "epoch: 1.66.0, loss: 0.5011860846975577\n",
      "epoch: 1.67.0, loss: 0.5319988041965459\n",
      "epoch: 1.68.0, loss: 0.4602380197138203\n",
      "epoch: 1.69.0, loss: 0.7686592155967535\n",
      "epoch: 1.70.0, loss: 0.6637616814763985\n",
      "epoch: 1.71.0, loss: 0.5717553829604323\n",
      "epoch: 1.72.0, loss: 0.5037985932868775\n",
      "epoch: 1.73.0, loss: 0.8595350368041832\n",
      "epoch: 1.74.0, loss: 0.6811920050352325\n",
      "epoch: 1.75.0, loss: 0.5228894517663576\n",
      "epoch: 1.76.0, loss: 0.5323196657520611\n",
      "epoch: 1.77.0, loss: 0.6824572337162249\n",
      "epoch: 1.78.0, loss: 0.6506137159392107\n",
      "epoch: 1.79.0, loss: 0.6528800415479501\n",
      "epoch: 1.80.0, loss: 0.598147749043232\n",
      "epoch: 1.81.0, loss: 0.5343175820896479\n",
      "epoch: 1.82.0, loss: 0.6629339413261381\n",
      "epoch: 1.83.0, loss: 0.82089638337808\n",
      "epoch: 1.84.0, loss: 0.6497792928534197\n",
      "epoch: 1.85.0, loss: 0.6776976316365131\n",
      "epoch: 1.86.0, loss: 0.4698181969138958\n",
      "epoch: 1.87.0, loss: 0.8260939774331156\n",
      "epoch: 1.88.0, loss: 1.015789853741963\n",
      "epoch: 1.89.0, loss: 0.8032010398570621\n",
      "epoch: 1.90.0, loss: 0.5906303821215074\n",
      "epoch: 1.91.0, loss: 0.5140095179402705\n",
      "epoch: 1.92.0, loss: 0.5762608536537026\n",
      "epoch: 1.93.0, loss: 0.6492067472105764\n",
      "epoch: 1.94.0, loss: 0.5286887523598385\n",
      "epoch: 1.95.0, loss: 0.5786760072804423\n",
      "epoch: 1.96.0, loss: 0.5653147454452386\n",
      "epoch: 1.97.0, loss: 0.5185737219311906\n",
      "epoch: 1.98.0, loss: 0.5953969186754025\n",
      "epoch: 1.99.0, loss: 0.493679030117355\n",
      "epoch 2/3\n",
      "epoch: 2.1.0, loss: 0.6653218334886242\n",
      "epoch: 2.2.0, loss: 0.5419095246626894\n",
      "epoch: 2.3.0, loss: 0.5267486451641417\n",
      "epoch: 2.4.0, loss: 0.36159751121712846\n",
      "epoch: 2.5.0, loss: 0.5887602071684293\n",
      "epoch: 2.6.0, loss: 0.8072820902884027\n",
      "epoch: 2.7.0, loss: 0.6607405272024249\n",
      "epoch: 2.8.0, loss: 0.5391787213320298\n",
      "epoch: 2.9.0, loss: 0.7818723612788098\n",
      "epoch: 2.10.0, loss: 0.5536318651122745\n",
      "epoch: 2.11.0, loss: 0.7888558339862515\n",
      "epoch: 2.12.0, loss: 0.5878988920847026\n",
      "epoch: 2.13.0, loss: 0.7286601807597411\n",
      "epoch: 2.14.0, loss: 0.6425673148452462\n",
      "epoch: 2.15.0, loss: 0.4519977699410682\n",
      "epoch: 2.16.0, loss: 0.6797236910433887\n",
      "epoch: 2.17.0, loss: 0.4271352413178646\n",
      "epoch: 2.18.0, loss: 0.30373960401632716\n",
      "epoch: 2.19.0, loss: 0.48861557703284036\n",
      "epoch: 2.20.0, loss: 0.42594872804944733\n",
      "epoch: 2.21.0, loss: 0.5296942771499554\n",
      "epoch: 2.22.0, loss: 0.3396788543417374\n",
      "epoch: 2.23.0, loss: 0.44812095779516686\n",
      "epoch: 2.24.0, loss: 0.39239885960199933\n",
      "epoch: 2.25.0, loss: 0.47160540345717455\n",
      "epoch: 2.26.0, loss: 0.36695467914321\n",
      "epoch: 2.27.0, loss: 0.552199255190869\n",
      "epoch: 2.28.0, loss: 0.4788449697086074\n",
      "epoch: 2.29.0, loss: 0.39547319430971684\n",
      "epoch: 2.30.0, loss: 0.4176078341607938\n",
      "epoch: 2.31.0, loss: 0.5370284961636559\n",
      "epoch: 2.32.0, loss: 0.32359650368498727\n",
      "epoch: 2.33.0, loss: 0.4296479586793069\n",
      "epoch: 2.34.0, loss: 0.4561950908444243\n",
      "epoch: 2.35.0, loss: 0.3561910797609355\n",
      "epoch: 2.36.0, loss: 0.5745895606502921\n",
      "epoch: 2.37.0, loss: 0.5529091715066925\n",
      "epoch: 2.38.0, loss: 0.45044721251621733\n",
      "epoch: 2.39.0, loss: 0.422455037098199\n",
      "epoch: 2.40.0, loss: 0.3650803746170647\n",
      "epoch: 2.41.0, loss: 0.5086624460198099\n",
      "epoch: 2.42.0, loss: 0.6265720199787339\n",
      "epoch: 2.43.0, loss: 0.5310158313049679\n",
      "epoch: 2.44.0, loss: 0.6040040132333185\n",
      "epoch: 2.45.0, loss: 0.46745397056336657\n",
      "epoch: 2.46.0, loss: 0.46521998390645236\n",
      "epoch: 2.47.0, loss: 0.5976332803864891\n",
      "epoch: 2.48.0, loss: 0.588705932381435\n",
      "epoch: 2.49.0, loss: 0.4587222536841139\n",
      "epoch: 2.50.0, loss: 0.5628481266491369\n",
      "epoch: 2.51.0, loss: 0.4657902267137818\n",
      "epoch: 2.52.0, loss: 0.7906091183685231\n",
      "epoch: 2.53.0, loss: 0.532304713087556\n",
      "epoch: 2.54.0, loss: 0.5811457335329936\n",
      "epoch: 2.55.0, loss: 0.4352632995774327\n",
      "epoch: 2.56.0, loss: 0.5317830544364258\n",
      "epoch: 2.57.0, loss: 0.3906363154480869\n",
      "epoch: 2.58.0, loss: 0.5481428587180894\n",
      "epoch: 2.59.0, loss: 0.6145145723421774\n",
      "epoch: 2.60.0, loss: 0.39553370637687285\n",
      "epoch: 2.61.0, loss: 0.31491229513102276\n",
      "epoch: 2.62.0, loss: 0.44518406761793494\n",
      "epoch: 2.63.0, loss: 0.5794030725526875\n",
      "epoch: 2.64.0, loss: 0.37126579715723823\n",
      "epoch: 2.65.0, loss: 0.559956517141652\n",
      "epoch: 2.66.0, loss: 0.36806889878603394\n",
      "epoch: 2.67.0, loss: 0.45192198735377\n",
      "epoch: 2.68.0, loss: 0.3769114416438601\n",
      "epoch: 2.69.0, loss: 0.6172125528771596\n",
      "epoch: 2.70.0, loss: 0.5055476340797861\n",
      "epoch: 2.71.0, loss: 0.5100692875158755\n",
      "epoch: 2.72.0, loss: 0.4678275205993944\n",
      "epoch: 2.73.0, loss: 0.7067915657930596\n",
      "epoch: 2.74.0, loss: 0.39457528337344594\n",
      "epoch: 2.75.0, loss: 0.4361053806978978\n",
      "epoch: 2.76.0, loss: 0.39320647642897893\n",
      "epoch: 2.77.0, loss: 0.5058382572520974\n",
      "epoch: 2.78.0, loss: 0.5509555666089383\n",
      "epoch: 2.79.0, loss: 0.5018396789799627\n",
      "epoch: 2.80.0, loss: 0.5256476398072383\n",
      "epoch: 2.81.0, loss: 0.347089417956322\n",
      "epoch: 2.82.0, loss: 0.4974816116830304\n",
      "epoch: 2.83.0, loss: 0.6445453351487391\n",
      "epoch: 2.84.0, loss: 0.3718097731582701\n",
      "epoch: 2.85.0, loss: 0.561810755091274\n",
      "epoch: 2.86.0, loss: 0.35506560707014306\n",
      "epoch: 2.87.0, loss: 0.7962015094452304\n",
      "epoch: 2.88.0, loss: 0.8260133969143457\n",
      "epoch: 2.89.0, loss: 0.7767547259703024\n",
      "epoch: 2.90.0, loss: 0.37338427343399205\n",
      "epoch: 2.91.0, loss: 0.3470467220494256\n",
      "epoch: 2.92.0, loss: 0.4681606938579001\n",
      "epoch: 2.93.0, loss: 0.5336158243295431\n",
      "epoch: 2.94.0, loss: 0.5765474489079727\n",
      "epoch: 2.95.0, loss: 0.5318386791121682\n",
      "epoch: 2.96.0, loss: 0.4781006992239365\n",
      "epoch: 2.97.0, loss: 0.4773690673762928\n",
      "epoch: 2.98.0, loss: 0.48499398739628036\n",
      "epoch: 2.99.0, loss: 0.42951798159756727\n"
     ]
    }
   ],
   "source": [
    "EPOCHES = 3\n",
    "\n",
    "for epoch in range(EPOCHES):\n",
    "    print(f\"epoch {epoch}/{EPOCHES}\")\n",
    "    loss_val = 0\n",
    "    for i, (img, label) in enumerate(zip(x_train[:10000], t_train[:10000])):\n",
    "\n",
    "        res = model.forward(img.reshape((1, 1, 28, 28))/255.0)\n",
    "        loss_val += model.backward(label)\n",
    "        if i % 100 == 0 and i > 0:\n",
    "            print(f\"epoch: {epoch}.{i//100}, loss: {loss_val/100}\")\n",
    "            loss_val = 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 81. 121.  95.  86.  94.  68.  72.  78.  64.  70.]\n",
      "[ 85. 126. 116. 107. 110.  87.  87.  99.  89.  94.]\n",
      "[100. 129. 114.  97. 113.  87.  83.  89. 102.  86.]\n"
     ]
    }
   ],
   "source": [
    "results = np.zeros((3, 10))\n",
    "for (img, label) in zip(x_test[:1000], t_test[:1000]):\n",
    "    results[0][label] += 1\n",
    "    r = model.forward(img.reshape((1, 1, 28, 28))/255.0)\n",
    "    if np.argmax(r, axis = 1) == label:\n",
    "        results[1][label] +=1\n",
    "    results[2][np.argmax(r, axis = 1)] += 1\n",
    "\n",
    "print(results[1])\n",
    "print(results[0])\n",
    "print(results[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.829"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(results[1])/np.sum(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97938144, 0.93103448, 0.76767677, 0.76344086, 0.91428571,\n",
       "       0.63043478, 0.88297872, 0.83760684, 0.8045977 , 0.7       ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[1]/results[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
